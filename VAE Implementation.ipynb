{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEarch(nn.Module):\n",
    "    def __init__(self, feature_size, latent_size):\n",
    "        super(VAEarch, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        # Encoder\n",
    "        self.fc1  = nn.Linear(feature_size, 128)\n",
    "        self.fc21 = nn.Linear(128, latent_size)\n",
    "        self.fc22 = nn.Linear(128, latent_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_size, 128)\n",
    "        self.fc4 = nn.Linear(128, feature_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        z_mu = self.fc21(h1)\n",
    "        z_var = self.fc22(h1)\n",
    "        return z_mu, z_var\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std) + mu\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z): \n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "    def __init__(self, A, B, model_path=None):\n",
    "        \n",
    "        # Set up model\n",
    "        self.model = VAEarch(A, B)\n",
    "        if model_path:\n",
    "            \n",
    "            self.load_model(model_path)\n",
    "        self.model = self.model\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-6)\n",
    "        \n",
    "    def test_sample(self, ds2):\n",
    "        self.model.eval()\n",
    "        train_loss = 0\n",
    "        l = []\n",
    "        for i,j in enumerate(ds2):\n",
    "            data = Variable(torch.from_numpy(j))\n",
    "            recon_batch, mu, logvar = self.model(data.float())\n",
    "            loss = self.loss_function(recon_batch, data.float(), mu, logvar)\n",
    "            train_loss += loss.data\n",
    "            l.append(loss.data)\n",
    "        mean = torch.mean(torch.stack(l))\n",
    "        return loss.data, recon_batch, data.float(), mu, logvar\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        l = []\n",
    "        for i,j in enumerate(ds1):\n",
    "            data = Variable(torch.from_numpy(ds1))\n",
    "            recon_batch, mu, logvar = self.model(data.float())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_function(recon_batch, data.float(), mu, logvar)\n",
    "            likelihood = self.log_likelihood(recon_batch, data.float(), mu, logvar)\n",
    "            loss.backward()\n",
    "            l.append(loss.data)\n",
    "            train_loss += loss.data\n",
    "            self.optimizer.step()\n",
    "        mean = torch.mean(torch.stack(l))\n",
    "        return loss.data, likelihood.data\n",
    "\n",
    "    def test(self, ds2):\n",
    "        self.model.eval()\n",
    "        train_loss = 0\n",
    "        l = []\n",
    "        for i,j in enumerate(ds2):\n",
    "            data = Variable(torch.from_numpy(j))\n",
    "            recon_batch, mu, logvar = self.model(data.float())\n",
    "            loss = self.loss_function(recon_batch, data.float(), mu, logvar)\n",
    "            train_loss += loss.data\n",
    "            l.append(loss.data)\n",
    "        mean = torch.mean(torch.stack(l))\n",
    "        return loss.data, recon_batch, data.float(), mu, logvar\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):    \n",
    "        BCE = F.binary_cross_entropy(recon_x, x)\n",
    "        KLD = 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return -1*(BCE + KLD)\n",
    "\n",
    "    def log_likelihood(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x)\n",
    "        return -1*BCE\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        torch.save(self.model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = np.loadtxt(\"book.ts.data\", delimiter=\",\", dtype=int)\n",
    "ds1 = np.loadtxt(\"book.valid.data\", delimiter=\",\", dtype=int)\n",
    "\n",
    "latent_size = 2\n",
    "vae = VAE(ds1.shape[1], latent_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 6):\n",
    "    vae.train()\n",
    "    vae.save_model('tae.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(ds1.shape[1], latent_size, model_path='tae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo_valid is tensor(-0.7775)\n",
      "elbo_test is tensor(-0.7784)\n",
      "loglikelihood value is  tensor(-0.7782)\n",
      "loglikelihood value is  tensor(-0.7784)\n"
     ]
    }
   ],
   "source": [
    "elbo_valid, recon_xv, xv, muv, logvarv = vae.test(ds1)\n",
    "print('elbo_valid is' ,elbo_valid)\n",
    "\n",
    "elbo_test, recon_xt, xt, mut, logvart = vae.test(ds2)\n",
    "print('elbo_test is', elbo_test)\n",
    "\n",
    "loglike_valid = vae.log_likelihood(recon_xv, xv, muv, logvarv)\n",
    "print('loglikelihood value is ',loglike_valid.detach())\n",
    "\n",
    "loglike_test = vae.log_likelihood(recon_xt, xt, mut, logvart)\n",
    "print('loglikelihood value is ',loglike_test.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:python vae_python.py <k> <modelfile-path> <data-set> <samples>\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv) != 5:\n",
    "        print(\"Usage:python vae_python.py <k> <modelfile-path> <data-set> <samples>\")\n",
    "else:\n",
    "    modelfile, dataset, samples = sys.argv[2], sys.argv[3], sys.argv[4]\n",
    "\n",
    "    ds1 = np.loadtxt(dataset, delimiter=\",\", dtype=int)\n",
    "    latent_size = 2\n",
    "    vae = VAE(ds1.shape[1], latent_size, model_path=modelfile)\n",
    "\n",
    "    iter_ = 0\n",
    "    while iter_<=samples:\n",
    "        elbo_valid, recon_xv, xv, muv, logvarv = vae.test_sample(ds1[iter_])\n",
    "        print('elbo_valid is' ,elbo_valid)\n",
    "\n",
    "        loglike_valid = vae.log_likelihood(recon_xv, xv, muv, logvarv)\n",
    "        print('loglikelihood value is ',loglike_valid.detach())\n",
    "        iter_ = iter_+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
